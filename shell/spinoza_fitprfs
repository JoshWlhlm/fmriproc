#!/usr/bin/env bash

#-----------------------------------------------------------------------------
# source setup and helper functions
source "${SETUP_FILE}"
source call_bashhelper

#-----------------------------------------------------------------------------
# Create help text
function Usage {
    cat <<USAGE

---------------------------------------------------------------------------------------------------
spinoza_fitprfs

Wrapper for call_prf that does the pRF-fitting using the output from pybest and the package pRFpy. 
There's several options for design matrix cases (in order of priority):
  - Place a design-matrix file called 'design_task-<TASK_NAME>.mat' in DIR_DATA_HOME/code
  - A directory with log-directories. A global search for a directory containing "Screenshots" is 
    done. If more directories are found and '--one-design' is specified, we'll take the first dir
    ectory
  - A directory with log-directories, but '--one-design' is NOT specified, meaning that each run 
    will get a separate design matrix. This can be useful if you have multiple conditions that 
    have different designs.

Usage:
  spinoza_fitprfs [arguments] [options] <input dir> <output dir> <png dir>

Arguments:
  -c <a,b,c,d>    list of values used for clipping of design matrix. Format must be [<top>,
                  <bottom>, <left>,<right>]. Negative values will be set to zero within 'fmriproc.
                  prf.get_prfdesign'
  -f <n_folds>    if your pRF experiment contains multiple equal sequences, you can use this flag
                  to perform within-run averaging before percent-changing in call_prf. This should
                  be in concert with number of volumes removed from the beginning of the 
                  timeseries                  
  -k <kwargs>     specify a file with additional arguments, similar to FreeSurfer's expert options.
                  See linescanning/misc/prf_options for an example. Please make sure you have a 
                  final empty white space at the end of the file, otherwise the parser gets confu-
                  sed. For VSCode: https://stackoverflow.com/a/44704969.
  -m <model>      one of ['gauss','dog','css','norm'] is accepted, default = "gauss"
  -n <session>    session ID (e.g., 1, 2, or none)
  -s <subject>    subject ID (e.g., 01). Can also be comma-separated list: 01,02,05
  -t <task ID>    If you have mutiple tasks specified in TASK_IDS or you just have multiple tasks 
                  and you want to run only one, specify the task name here ('task-rest' is 
                  ignored). You can also specify multiple tasks if you want to bypass the setup 
                  file completely. In that case, use the format '-t <task1>,<task2>,<task3>'
  -x <constr>     String or list of constraints to use for the gaussian and extended stage. By 
                  default, we'll use trust-constr minimization for both stages, but you can speed 
                  up the extended models with L-BGFS. Note that if you want the same minimizer for 
                  both stages, you can use the '--tc' or '--bgfs' tags. This input specifically 
                  allows you to specify a list of different minimizers for each stage, e.g., 
                  trust-constr for Gaussian model, and L-BGFS for extended model. The format 
                  should be '-x "tc,bgfs"'
  -j <n_cpus>     number of jobs to parallellize over; default is 10
  -q <queue>      submit jobs to a specific queue. Defaults to SGE_QUEUE_LONG in spinoza_setup
  -r <TR>         set repetition time (TR) manually. Defaults to 1.5 if input != gifti's. Otherwise
                  we'll read it from gifti-files with 'dataset.ParseGiftiFile'
  -v <n_vols>     number of volumes to cut from the beginning of the timeseries (default = None)

Options:
  -h|--help       print this help text
  -o|--ow         delete existing file and re-run analysis fully. Even if 'model=norm', we'll over-
                  write the Gaussian parameters. If not specified, and 'model=norm' while Gaussian 
                  parameters already exist, we'll inject them into the DN-model.
  --bgfs          use L-BGFS minimization for both the Gaussian as well as the extended model. Use 
                  the '-x'flag if you want different minimizers for both stages
  --bold          re-calculate the BOLD timecourses; otherwise use existing 
                  '*hemi-LR_desc-avg_bold.npy'   
  --fsaverage     overwrite PYBEST_SPACE-variable and use FSAverage for fitting (see your setup 
                  file)
  --fsnative      overwrite PYBEST_SPACE-variable and use FSNative for fitting (see your setup 
                  file)
  --fix-hrf       fit the HRF going from Gaussian iterative fit to further fitting
  --grid          only run grid fit, skip iterative fit
  --no-hrf        do NOT fit the HRF during pRF-fitting. See 'call_prf' for more information
  --separate-hrf  fit the HRF in two stages. See 'call_prf' for more information
  --local         run locally even though we have SGE available.
  --merge-ses     average pRF data from all sessions
  --multi-design  specifies that for all runs in the dataset have run-/task-specific screenshot di-
                  rectories. This requires that the directory names you saved must match your 
                  naming 
                  scheme of functional files as we'll match on run-/task-ID
  --nelder        Use Nelder-Mead method for minimization.
                  Use the '-x' flag if you want different minimizers for both stages
  --no-clip       ensures that the design matrix is NOT clipped, despite the possible presence of 
                  screen delimiter files
  --no-fit        Stop the process before fitting, right after saving out averaged data. This was 
                  useful for me to switch to percent-signal change without requiring a re-fit.
  --save-grid     Save out gridsearch parameters
  --no-bounds     Turn off grid bounds; sometimes parameters fall outside the grid parameter 
                  bounds, causing 'inf' values. This is especially troublesome when fitting a 
                  single timecourse. If you trust your iterative fitter, you can turn off the 
                  bounds and let the iterative take care of the parameters
  --raw           use the raw, un-zscore'd output from pybest, rather than percent signal change
  --refit         refit existing data; uses a simplified call to fmriproc.prf.pRFmodelFitting 
                  using call_prfrefit
  --tc            use trust-constr minimization for both the Gaussian as well as the extended 
                  model. Use the '-x' flag if you want different minimizers for both stages
  --zscore        use the zscore'd output from pybest, rather than percent signal change. If not 
                  specified, percent signal change is implemented as follows:

                    psc = signals*100/(mean(signals)) - median(signals_without_stimulus)

  --v1|--v1       only fit voxels from ?.V1/2_exvivo.thresh.label; the original dimensions will be 
                  maintained, but timecourses outside of the ROI are set to zero
  --sge           submit job to cluster (SGE/SLURM)

Positional:
  <input dir>     base input directory with pybest data (e.g., '\$DIR_DATA_DERIV/pybest'). You can 
                  also point to the fmriprep-folder, in which case the gifti's of 'fsnative' will 
                  be used.
  <output dir>    base output directory for prf data (e.g., '\$DIR_DATA_DERIV/prf')
  <png dir>       base path of where sourcedata of subjects live. In any case, the subject ID will 
                  be appended to this path (if applicable, so will session ID). Inside THAT 
                  directory, we'll search for directories with 'Screenshots'. So, if you specify 
                  \$DIR_DATA_SOURCE for 'sub-005' and 'ses-1', we'll search in DIR_DATA_SOURCE/
                  sub-005/ses-1/* for directories with "Screenshots". If multiple directories are 
                  found, it depends on the options which directory is used: 
                    - if --multi-design is specified, each directory will be matched with its 
                      corresponding functional run. 
                    - If not, we'll take the 1st directory in the list.

Models for pRF fitting:
  --gauss         run standard Gaussian model (default) [Dumoulin & Wandell, 2008]
  --dog           run difference-of-gaussian model (suppression) [Zuiderbaan, et al. 2013]
  --css           run compressive spatial summation model (compression) [Kay, et al. 2013]
  --norm          run divisive normalization model (suppresion+compression) [Aqil, et al. 2021]
  --abd           DN-model with fixed C-parameter [Aqil, et al. 2021]
  --abc           DN-model with fixed D-parameter [Aqil, et al. 2021]

Eample:
  spinoza_fitprfs \$DIR_DATA_DERIV/prf \$DIR_DATA_DERIV/pybest \$DIR_DATA_SOURCE
  spinoza_fitprfs -s 001 -n 1 \$DIR_DATA_DERIV/prf \$DIR_DATA_DERIV/pybest \$DIR_DATA_SOURCE
  spinoza_fitprfs --multi-design \$DIR_DATA_DERIV/prf \$DIR_DATA_DERIV/pybest \$DIR_DATA_SOURCE
  spinoza_fitprfs -o \$DIR_DATA_DERIV/prf \$DIR_DATA_DERIV/pybest \$DIR_DATA_SOURCE

Call with master:
  # vanilla (runs gaussian model)
  master -m $(get_module_nr $(basename ${0})) -s 01

  # norm+submit
  master -m $(get_module_nr $(basename ${0})) -s 01 --norm -j 25 --sge

  # use l-bgfs for all stages
  master -m $(get_module_nr $(basename ${0})) -s 01 --norm -j 25 --sge --bgfs

  # refit existing parameters
  master -m $(get_module_nr $(basename ${0})) -s 01 --norm -j 25 --sge --refit

---------------------------------------------------------------------------------------------------

USAGE

}

# Check for subject & session flags
OW=0
OW_flag=""
run_local=1
grid_flag=""
multi_design=0
fit_hrf=""
zscore_flag=""
raw_flag=""
verb_flag=""
clip_flag=""
clip=1
use_constr="--tc"
fit_flag=""
cut_vols=""
lbl_flag=""
save_grid=""
bounds_flag=""
merge_flag=""
jobs_flag=""
model="gauss"
n_cpus=5
kwargs_file=""
tr_flag=""
use_space=${PYBEST_SPACE}
refit_data=0
n_pix=100
redo_bold=""
folds_flag=""
skip_flag=""
trans_flag=""
fix_hrf=""
bold_flag=""
dm_flag=""
par_flag=""
SGE_QUEUE=${SGE_QUEUE_LONG}

while getopts :-:hlos:n:m:t:x:c:v:j:k:q:r:p:f: argument
do
  case ${argument} in
    -)
      case "${OPTARG}" in
        multi-design)
          multi_design=1
          ;;           
        no-hrf)
          fit_hrf="--no-hrf"
          ;;  
        separate-hrf)
          fit_hrf="--separate-hrf"
          ;;             
        gauss)
          model="gauss"
          ;;  
        dog)
          model="dog"
          ;;   
        css)
          model="css"
          ;;  
        norm)
          model="norm"
          ;;       
        abc)
          model="abc"
          ;;     
        abd)
          model="abd"
          ;;                                                        
        zscore)
          zscore_flag="--zscore"
          ;;  
        raw)
          raw_flag="--raw"
          ;;   
        verbose)
          verb_flag="--verbose"
          ;;
        no-clip)
          clip=0
          ;;    
        local)
          run_local=1
          ;;       
        grid)
          grid_flag="--grid"
          ;;
        tc)
          use_constr="--tc"
          ;;
        nelder)
          use_constr="--nelder"
          ;;          
        bgfs)
          use_constr="--bgfs"
          ;;    
        no-fit)
          fit_flag="--no-fit"
          ;;      
        save-grid)
          save_grid="--save-grid"
          ;;            
        v1)
          lbl_flag="--v1"
          ;;
        v2)
          lbl_flag="--v2"
          ;;      
        no-bounds)
          bounds_flag="--no-bounds"
          ;;     
        merge-ses)
          merge_flag="--merge-ses"
          ses_id="avg"
          ;;        
        fsaverage)
          use_space="fsaverage"
          ;; 
        fsnative)
          use_space="fsnative"
          ;;                 
        refit)
          refit_data=1
          ;;  
        bold)
          redo_bold="--bold"
          ;;        
        skip-settings)
          skip_flag="--skip-settings"
          ;;     
        transpose)
          trans_flag="--transpose"
          ;; 
        fix-hrf)
          fix_hrf="--fix-hrf"
          ;;
        sge)
          run_local=0
          ;;  
        ow)
          OW=1
          ;;                    
        help)
          Usage && exit 0
          ;;                      
        *)
          Usage
          print_error_msg "$(basename ${0})" "getopt" "Unknown option --${OPTARG}"
          exit 1
          ;;
      esac
      ;;
    h)  Usage && exit 0
          ;;
    s)  sub=${OPTARG}
          ;;
    n)  ses=${OPTARG}
          ;;
    m)  model=${OPTARG}
          ;;
    t)  task_ID=${OPTARG}
          ;;                                       
    o)  OW=1
        OW_flag="--overwrite"
          ;;
    c)  clipper=${OPTARG}
          ;; 
    p)  n_pix=${OPTARG}
          ;;          
    j)  n_cpus=${OPTARG}
          ;;               
    x)  use_constr="--constr [${OPTARG[@]}]"
          ;;
    v)  cut_vols="--cut-vols ${OPTARG[@]}"
          ;;        
    k)  kwargs_file="--kwargs ${OPTARG}"
          ;;       
    q)  SGE_QUEUE=${OPTARG}
          ;;  
    r)  tr_flag="--tr ${OPTARG}"
          ;;       
    f)  folds_flag="--folds ${OPTARG}"
          ;;                                    
  esac
done

if [[ $# -lt 3 ]] ; then
  Usage && exit 0
fi

INPUT=${@:$OPTIND:1}
OUTPUT=${@:$OPTIND+1:1}
PNG=${@:$OPTIND+2:1}

if [[ -z ${sub} ]]; then
  # loop through subjects
  search="${INPUT}/${SUBJECT_PREFIX}*"
else
  # read specified subjects into array
  IFS=', ' read -r -a search <<< "${sub}"
  search=${search[@]}
  unset IFS
fi

#-----------------------------------------------------------------------------
# intro
start_timer "pRF-fitting with pRFpy"

#-----------------------------------------------------------------------------
# loop through subjects
for subID in ${search}; do

  #-----------------------------------------------------------------------------
  # collect subject name
  sub_name=$(collect_subject_name "$sub" "$subID" "$SUBJECT_PREFIX")
  sub_id=$(get_subject_id "$sub" "$subID" "$SUBJECT_PREFIX")
  read base_path base <<< "$(collect_session_info "$ses" "$sub_name")"

  #-----------------------------------------------------------------------------
  # set paths
  if [[ -z ${merge_flag} ]]; then
    input_dir="${INPUT}/${base_path}"
    prf_dir="${OUTPUT}/${base_path}"
  else
    input_dir="${INPUT}/${sub_name}"
    prf_dir="${OUTPUT}/${sub_name}"
  fi

  # png dir
  png_dir="${PNG}/${sub_name}"

  #-----------------------------------------------------------------------------
  # check if we got model specification
  if [[ -z ${model} ]]; then
    use_model="gauss"
  else
    allowed_models=("gauss" "css" "dog" "norm" "abc" "abd")
    # https://stackoverflow.com/a/15394738
    if [[ " ${allowed_models[*]} " =~ " ${model} " ]]; then
      use_model=$(make_lower ${model})
    else
      echo
      print_line -  
      print_error_msg "$(basename ${0})" "model" "model specified was \"${model}\". Please use on of '${allowed_models[@]}'"
      exit 1
    fi
  fi

  #-----------------------------------------------------------------------------
  # look for parameter file
  if [[ ${grid_only} -eq 1 ]]; then
    txt="grid-fit only with model ${use_model}"
    stage="stage-grid"
  else
    txt="iter-fit with model ${use_model}" 
    stage="stage-iter"
  fi

  #-----------------------------------------------------------------------------
  # check if input is pybest or fmriprep
  if [[ $(basename "${INPUT}") == "pybest" ]]; then
    if [[ ! -z ${zscore_flag} ]]; then
      use_dir="denoising" # directly use pybest output (= zscored)
    else
      use_dir="unzscored" # we requested percent signal change; use output from call_unzscore
    fi

    if [[ -z ${merge_flag} ]]; then 
      full_input="${input_dir}/${use_dir}"
      pyb_flag=""
    else
      full_input="${input_dir}"
      pyb_flag="--pyb-type ${use_dir}"
    fi
  elif [[ $(basename "${INPUT}") == "fmriprep" ]]; then
    # internally, call_prf uses utils.FindFiles, which searches for files recursively. No futher addition is required
    full_input="${input_dir}"
  fi

  #-----------------------------------------------------------------------------
  # do stuff if input directory exists
  if [[ -d "${full_input}" || ${refit_data} -eq 1 ]]; then

    # print header
    print_subject_header ${sub_name}

    if [[ ! -d "${prf_dir}" ]]; then
      mkdir -p "${prf_dir}"
    fi
    
    #-----------------------------------------------------------------------------
    # fetch PNG-directories, sort, and save in array
    PNG_UNSORTED=$(
      find "${png_dir}" \
      -type d \
      -name "*Screenshots*" \
      2>/dev/null
    )

    IFS=$'\n' PNGS_DIR=($(sort <<<"${PNG_UNSORTED[*]}"))
    unset IFS    
    
    #-----------------------------------------------------------------------------
    # check if we got custom specified task ID; otherwise loop through task IDs from setup file
    if [[ ! -z ${task_ID} ]]; then
      IFS=', ' read -r -a search_tasks <<< "${task_ID}"
      unset IFS
    else
      search_tasks=${TASK_IDS[@]}
    fi

    #-----------------------------------------------------------------------------
    # loop through tasks
    echo "Running pRF-analysis; ${txt}"
    for task in ${search_tasks[@]}; do

      #-----------------------------------------------------------------------------
      # Check if we should overwrite file
      if [[ ! -z ${lbl_flag} ]]; then
        if [[ ${lbl_flag} == *"v1"* ]]; then
          roi="V1"
        elif [[ ${lbl_flag} == *"v2"* ]]; then
          roi="V2"
        else
          echo
          print_line -  
          print_error_msg "$(basename ${0})" "roi" "the flag '${lbl_flag}' was specified, but there is only support for '--v1'/'--v2'"
          exit 1
        fi

        # find existing parameters
        prf_params=$(
          find "${prf_dir}" \
          -type f \
          -name "*${use_model}*" \
          -and -name "*roi-${roi}*" \
          -and -name "*${stage}*" \
          -and -name "*task-${task}*" \
          -and -name "*prf_params.pkl" \
          2>/dev/null
        )
      else
        # no ROI
        prf_params=$(
          find "${prf_dir}" \
          -type f \
          -name "*${use_model}*" \
          -and -name "*${stage}*" \
          -and -name "*task-${task}*" \
          -and -name "*prf_params.pkl" \
          -and -not -name "*roi-*" \
          2>/dev/null
        )
      fi
      
      if [[ ${OW} -eq 1 ]]; then
        rm -r "${prf_params}" 2>/dev/null
      fi

      #-----------------------------------------------------------------------------
      # run stuff if file doesn't exist
      if [[ ! -f "${prf_params}" ]] || [[ ! -z ${fit_flag} ]] || [[ ${refit_data} -eq 1 ]]; then

        # exclude rest as task
        if [[ ${task} != "rest" ]]; then

          echo "Dealing with task-ID: ${task}"

          #-----------------------------------------------------------------------------
          # decide on design matrix for tasks in TASK_IDS
          if [[ ${multi_design} -eq 0 ]]; then

            if [[ ! -z ${task_ID} ]]; then
              echo
              print_line -
              echo "WARNING in $(basename ${0}): custom task \"${task_ID}\" was/were specified, but \"--multi-design\"-flag omitted."
              echo "This may result in selection of the wrong png-folder. Please rerun with \"--multi-design\""
              exit 2
            fi

            #-----------------------------------------------------------------------------
            # sort out design matrix
            proj_dm="${DIR_DATA_HOME}/code/design_task-${task}.mat"
            final_dm="${prf_dir}/design_task-${task}.mat"

            # 1) design exists in "code"-folder
            if [[ -f "${proj_dm}" ]]; then
              echo -e "Creating symlink to ${BOLD_GREEN}${proj_dm}${RESET}"
              ln -s "${proj_dm}" "${final_dm}" 2>/dev/null
              use_pngdir="${proj_dm}"
            elif [[ -f "${final_dm}" ]]; then
              # 2) dm exists in subject folder
              use_pngdir="${final_dm}"
            else
              # 3) create design from PNGs
              if [[ ! -z "${PNGS_DIR}" ]]; then
                use_pngdir="${PNGS_DIR[0]}"
              else
                echo
                print_line -
                print_error_msg "$(basename ${0})" "call_winsorize" "could not find png's in \"${png_dir}\""
                echo "Some solutions could be:"
                echo " - Create \"${DIR_DATA_HOME}/code/design_task-${task}.mat\""
                echo " - Create \"${prf_dir}/design_task-${task}.mat\""
                echo " - Put directories containing \"Screenshots\"-directory in \"${png_dir}\""
                exit 1
              fi

              # check if directory contains png-files
              pngs=$(
                find "${use_pngdir}" \
                -type f \
                -name "*.png" \
                2>/dev/null
              ) 
                
              if [[ -z "${pngs[@]}" ]]; then
                echo
                print_line -  
                print_error_msg "$(basename ${0})" "find" "no *.png-files in \"${use_pngdir}\""
                exit 1
              fi
            fi
            
          else
            #-----------------------------------------------------------------------------
            # multi-session pRF setup

            # how cool; list comprehension-like structure in bash
            # https://stackoverflow.com/a/6721137
            if [[ ! -z "${PNGS_DIR}" ]]; then
              task_dirs=(
                $(
                  for x in ${PNGS_DIR[@]}; do
                    if [[ ${x} == *"task-${task}"* ]]; then
                      echo "${x}"
                    fi
                  done
                )
              )

              # select first directory if many exist
              if [[ ! -z "${task_dirs}" ]]; then

                use_pngdir="${task_dirs[0]}"
                pngs=$(
                  find "${use_pngdir}" \
                  -type f \
                  -name "*.png" \
                  2>/dev/null
                ) 
                  
                # check if directory contains png-files
                if [[ -z "${pngs[@]}" ]]; then
                  echo
                  print_line -  
                  print_error_msg "$(basename ${0})" "find" "no *.png-files in \"${use_pngdir}\""
                  exit 1
                fi
              else
                echo
                print_line -  
                print_error_msg "$(basename ${0})" "find" "Could not find \"task-${task}\" folders in ${BOLD_GREEN}${PNGS_DIR}${RESET}"
              fi
            else
              echo
              print_line -
              print_error_msg "$(basename ${0})" "call_winsorize" "could not find png's in \"${png_dir}\""
              echo "Some solutions could be:"
              echo " - Create \"${DIR_DATA_HOME}/code/design_task-${task}.mat\""
              echo " - Create \"${prf_dir}/design_task-${task}.mat\""
              echo " - Put directories containing \"Screenshots\"-directory in \"${png_dir}\""
              exit 1
            fi
          fi

          echo "Using \"${use_pngdir}\" for design matrix"

          #-----------------------------------------------------------------------------
          # check delimiter file (should be json file) if clip=1 (can be set to 0 by --no-clip)
          if [[ ${clip} -eq 1 ]]; then

            # check if we got manual clip information
            if [[ -z ${clipper} ]]; then

              if [[ -d "${use_pngdir}" ]]; then
                # check first if we have a json file
                screen_=$(
                  find "$(dirname ${use_pngdir})" \
                  -type f \
                  -name "*screen.json" \
                  2>/dev/null
                )

                if [[ -f "${screen_}" ]]; then
                  clip_flag="--clip ${screen_}"
                else
                  # if not, check if we have yml file (should contain "screen_delim"-key)
                  screen_=$(
                    find "$(dirname ${use_pngdir})" \
                    -type f \
                    -name "*.yml" \
                    2>/dev/null
                  )
                  if [[ -f "${screen_}" ]]; then

                    # check if we have "screen_delim"-key in yml file
                    if [[ ! -z $(grep "screen_delim" ${screen_}) ]]; then
                      clip_flag="--clip ${screen_}"
                    else
                      clip_flag=""
                    fi
                    
                  else
                    clip_flag=""
                  fi
                fi
              fi
            else
              clip_flag="--clip ${clipper}"
            fi
          fi

          #-----------------------------------------------------------------------------
          # decide how to execute the process
          if [[ ${refit_data} -eq 0 ]]; then
            script_name="call_prf"
          else
            script_name="call_refit"

            #-----------------------------------------------------------------------------
            # check bold file/ design matrix
            bold_file=$(
              find "${prf_dir}" \
              -type f \
              -name "*hemi-LR_*" \
              -and -name "*avg_bold.npy" \
              2>/dev/null
            )

            if [[ ! -f "${bold_file}" ]]; then
              print_file_not_in_dir "${sub-name}" "\"hemi-LR\" and \"avg_bold.npy\"" "${prf_dir}"
              exit 1
            fi

            # design file should exist by now
            dm_file="${prf_dir}/design_task-${task}.mat"
            if [[ ! -f '${dm_file}' ]]; then
              print_file_not_exist "${sub_name}" "${dm_file}"
              exit 1
            fi
             
            bold_flag="--input ${bold_file}"
            dm_flag="--dm ${dm_file}"

            # old params
            if [[ ! -z "${prf_params}" ]]; then
              echo "Refitting \"${prf_params}\""
              
              # rename iter fit to grid; iter will be the refitted data
              if [[ "${prf_params}" == *"stage-iter"* ]]; then
                file_grid="${prf_params//stage-iter/stage-grid}"
                cp "${prf_params}" "${file_grid}" 2>/dev/null
              fi
              par_flag="--old ${prf_params}"
            fi
          fi

          #-----------------------------------------------------------------------------
          # decide job
          job="$(
            decide_job_type \
            "${script_name}" \
            "${base}_task-${task}_model-${model}" \
            "${run_local}" \
            "${prf_dir}" \
            "${n_cpus}" \
            "${SGE_QUEUE}"
          )"

          #-----------------------------------------------------------------------------
          # define call to call_prf
          export DISPLAY=:0
          cmd=(
            "${job}"
            "${grid_flag}"
            "${fit_hrf}"
            "${clip_flag}"
            --sub "${sub_id}"
            --ses "${nr}"
            --task "${task}"
            --outputdir "${prf_dir}"
            --inputdir "${full_input}"
            --png "${use_pngdir}"
            --space "${use_space}"
            --${use_model}
            --jobs "${n_cpus}"
            --n-pix "${n_pix}"
            "${pyb_flag}"
            "${folds_flag}"
            "${tr_flag}"
            "${kwargs_file}"
            "${save_grid}"
            "${lbl_flag}"
            "${zscore_flag}"
            "${raw_flag}"
            "${verb_flag}"
            "${OW_flag}"
            "${use_constr}"
            "${fit_flag}"
            "${cut_vols}"
            "${bounds_flag}"
            "${merge_flag}"
            "${bold_flag}"
            "${dm_flag}"
            "${redo_bold}"
            "${skip_flag}"
            "${trans_flag}"
            "${par_flag}"
            "${fix_hrf}"
          )

          # print and run
          if [[ ${run_local} -eq 1 ]]; then
            print_cmd "${cmd[@]}"
          fi

          cmd_file="${prf_dir}/sub-${sub_id}_ses-${nr}_task-${task}_desc-command.txt"
          (
            echo "### New invocation of ${script_name} @$(date)"
            echo "$(echo ${cmd[@]} | xargs)"
            echo
          ) >> "${cmd_file}"

          eval "${cmd[@]}"
          if [[ $? -ne 0 ]]; then
            echo
            print_line -
            print_error_msg "$(basename ${0})" "${script_name}"
            exit 1
          fi
        fi
      else
        print_output_exists "${sub_name}" "${prf_params}"
        continue
      fi
    done
  else
    print_directory_not_exist "${sub_name}" "${full_input}"
  fi
done

#-----------------------------------------------------------------------------
# outro
end_timer
